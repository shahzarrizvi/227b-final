{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ba8ec-be80-40cb-ac04-6ff4ae62defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random graphs.\n",
    "from networkx.generators.random_graphs import erdos_renyi_graph\n",
    "from networkx.generators.random_graphs import barabasi_albert_graph\n",
    "from networkx.generators.community import stochastic_block_model\n",
    "from networkx.generators.random_graphs import watts_strogatz_graph\n",
    "from networkx.generators.community import random_partition_graph\n",
    "\n",
    "# Standard imports\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import math\n",
    "from tqdm import tqdm\n",
    "#import seaborn as sns\n",
    "#from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "#import random\n",
    "#from deeprobust.graph.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a5844d-e700-4570-8bad-f0739df4253e",
   "metadata": {},
   "source": [
    "The code in this notebook is adapted from the paper \"A Unified Framework for Optimization-Based\n",
    "Graph Coarsening\\\" by Kumar et. al (2023)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b0febe-dc3a-4dac-99b7-f0faf7b18c9a",
   "metadata": {},
   "source": [
    "# Graph Coarsening Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda19616-1477-4934-a659-ef6e4c8b4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphCoarsener:\n",
    "    def __init__(self, L, X, n, gamma, lambd, alpha, seed = 666):\n",
    "        # Save parameter fields.\n",
    "        self.L = L\n",
    "        self.X = X\n",
    "        self.N = X.shape[0]\n",
    "        self.n = n\n",
    "        self.d = X.shape[1]\n",
    "        \n",
    "        # Initialize optimization variables as random matrices.\n",
    "        np.random.seed(seed)\n",
    "        self.X_tilde = np.random.normal(0, 1, (n, d))\n",
    "        \n",
    "        self.clip = 1e-10\n",
    "        self.C = np.random.normal(0, 1, (N, n))\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        # Save regularization variables.\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Optimization parameters.\n",
    "        self.num_iter = 0\n",
    "        self.lr = 1e-5\n",
    "        NUM_C_ITER = 100\n",
    "\n",
    "    def objective(self):\n",
    "        f = 0\n",
    "        \n",
    "        # Bregman divergence.\n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        f += -self.gamma * np.linalg.slogdet(self.C.T @ self.L @ self.C + J)[1]\n",
    "        \n",
    "        # Dirichlet energy.\n",
    "        L_tilde = self.C.T @ self.L @ self.C\n",
    "        f += np.trace(self.X_tilde.T @ L_tilde @ self.X_tilde)\n",
    "\n",
    "        # Regularization for C.\n",
    "        f += self.lambd * np.linalg.norm(self.C @ np.ones((self.n, 1)))**2 / 2\n",
    "        \n",
    "        # Regularization for X_tilde.\n",
    "        f += self.alpha * np.linalg.norm(self.X - self.C @ self.X_tilde)**2 / 2\n",
    "        \n",
    "        return f\n",
    "\n",
    "    def update_X_tilde(self):\n",
    "        L_tilde = self.C.T @ self.L @ self.C\n",
    "        A = 2 * L_tilde / self.alpha + self.C.T @ self.C\n",
    "        self.X_tilde = np.linalg.pinv(A) @ self.C.T @ X\n",
    "\n",
    "        for i in range(len(self.X_tilde)):\n",
    "            self.X_tilde[i] = self.X_tilde[i] / np.linalg.norm(self.X_tilde[i])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def gradient_C(self):\n",
    "        grad = np.zeros(self.C.shape)\n",
    "        \n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        v = np.linalg.pinv(self.C.T @ self.L @ self.C + J)\n",
    "        grad += -2*self.gamma * self.L @ self.C @ v\n",
    "        \n",
    "        grad += self.alpha * (self.C @ self.X_tilde - self.X) @ self.X_tilde.T\n",
    "        grad += 2*self.L @ self.C @ self.X_tilde @ self.X_tilde.T\n",
    "        grad += self.lambd * np.abs(self.C) @ (np.ones((self.n, self.n)))\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def update_C(self):\n",
    "        self.C = self.C - self.lr * self.gradient_C()\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        for i in range(len(self.C)):\n",
    "            self.C[i] = self.C[i] / np.linalg.norm(self.C[i],1)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def fit(self, num_iters):\n",
    "        loss = np.zeros(num_iters)\n",
    "        for i in tqdm(range(num_iters)):\n",
    "            for _ in range(NUM_C_ITER):\n",
    "                self.update_C()\n",
    "            self.update_X_tilde()\n",
    "            loss[i] = self.objective()\n",
    "            self.num_iter += 1\n",
    "        return (self.C, self.X_tilde, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e57a4-3f7a-4d74-8239-538c4a8ce73d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Random Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbffa5c3-ec5a-4f82-8d48-cd6152c80750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 65.   0.   0. ...   0.   0.   0.]\n",
      " [  0.  90.  -9. ...   0.   0.   0.]\n",
      " [  0.  -9. 145. ...   0.   0.   0.]\n",
      " ...\n",
      " [  0.   0.   0. ...  96.   0.   0.]\n",
      " [  0.   0.   0. ...   0.  97.   0.]\n",
      " [  0.   0.   0. ...   0.   0.  27.]]\n",
      "(500, 500)\n"
     ]
    }
   ],
   "source": [
    "# Some Input parameters.\n",
    "np.random.seed(666)\n",
    "N = 500 # number of nodes\n",
    "p = 0.1\n",
    "#graph = erdos_renyi_graph(N, p, directed = False)\n",
    "#graph = nx.barabasi_albert_graph(n = N, m = 20)\n",
    "#graph = watts_strogatz_graph(N, 20, p, seed = 666)\n",
    "graph = nx.random_geometric_graph(N, p)\n",
    "\n",
    "\n",
    "# DISPLAY GENERATED GRAPH.\n",
    "#print(graph.edges)\n",
    "#print(graph.nodes)\n",
    "\n",
    "# PLOTTING GENERATED GRAPH.\n",
    "#nx.draw(graph, with_labels = True)\n",
    "#plt.title(\"Laplacian\")\n",
    "#plt.show()\n",
    "\n",
    "# CREATING EDGE WEIGHTS.\n",
    "np.random.seed(666)\n",
    "W = np.zeros((N, N))\n",
    "for (x, y) in graph.edges:\n",
    "    W[x][y] = np.random.randint(1,10)\n",
    "W = W + W.T\n",
    "\n",
    "# CALCULATING LAPLACIAN MATRIX OF GENERATED GRAPH.\n",
    "D = np.diag(W @ np.ones((W.shape[0])))\n",
    "L = D - W\n",
    "print(L)\n",
    "print(L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5632b450-07b0-441d-bd12-6640206cfda6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.25374963e-02  1.79055906e-01  2.13773962e-02 ...  1.89392113e-01\n",
      "  -1.47952522e-01 -2.29413576e-01]\n",
      " [ 1.13106317e-01 -2.25278824e-01  1.75945720e-02 ... -3.16192104e-01\n",
      "  -4.84635585e-02 -1.09480817e-01]\n",
      " [ 2.94350902e-01 -1.69274694e-01 -6.18232059e-02 ... -1.91962654e-01\n",
      "   1.41152207e-02  2.26638180e-01]\n",
      " ...\n",
      " [-1.24959422e-01 -2.66503152e-01  7.34824476e-02 ... -2.78030129e-01\n",
      "  -3.63077697e-02 -3.70847386e-02]\n",
      " [ 2.54938151e-04  1.81113082e-01 -1.39548050e-01 ... -4.98979170e-02\n",
      "  -1.14394233e-02  7.64733940e-02]\n",
      " [ 1.52676741e-01  2.42150694e-01  3.23388109e-01 ... -2.07616538e-01\n",
      "   2.58863465e-01  4.00311933e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Create features for the synthetic graph\n",
    "d = 250\n",
    "X = np.random.multivariate_normal(np.zeros(N), np.linalg.pinv(L), d).T\n",
    "X.shape\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a4dc976-d168-4c2d-a0ec-5b1251b0da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphCoarsener:\n",
    "    def __init__(self, L, X, n, gamma, lambd, alpha, seed = 666):\n",
    "        # Save parameter fields\n",
    "        self.L = L\n",
    "        self.X = X\n",
    "        self.N = X.shape[0]\n",
    "        self.n = n\n",
    "        self.d = X.shape[1]\n",
    "        \n",
    "        # Randomly initialize optimization variables\n",
    "        np.random.seed(seed)\n",
    "        self.X_tilde = np.random.normal(0, 1, (n, d))\n",
    "        \n",
    "        self.clip = 1e-10\n",
    "        self.C = np.random.normal(0, 1, (N, n))\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        # Save regularization variables\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Optimization parameters\n",
    "        self.num_iter = 0\n",
    "        self.lr = 1e-5\n",
    "        MAX_C_ITER = 100\n",
    "\n",
    "    def objective(self):\n",
    "        f = 0\n",
    "        \n",
    "        # Bregman divergence\n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        f += -self.gamma * np.linalg.slogdet(self.C.T @ self.L @ self.C + J)[1]\n",
    "        \n",
    "        # Dirichlet energy\n",
    "        L_tilde = self.C.T @ self.L @ self.C\n",
    "        f += np.trace(self.X_tilde.T @ L_tilde @ self.X_tilde)\n",
    "        \n",
    "        # Regularization for X_tilde\n",
    "        f += self.alpha * np.linalg.norm(self.X - self.C @ self.X_tilde)**2 / 2\n",
    "        \n",
    "        # Regularization for C\n",
    "        f += self.lambd * np.linalg.norm(self.C @ np.ones((self.n, 1)))**2 / 2\n",
    "        \n",
    "        return f\n",
    "\n",
    "    def update_X_tilde(self):\n",
    "        L_tilde = self.C.T @ self.L @ self.C\n",
    "        A = 2 * L_tilde / self.alpha + self.C.T @ self.C\n",
    "        self.X_tilde = np.linalg.pinv(A) @ self.C.T @ X\n",
    "\n",
    "        for i in range(len(self.X_tilde)):\n",
    "            self.X_tilde[i] = self.X_tilde[i] / np.linalg.norm(self.X_tilde[i])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def gradient_C(self):\n",
    "        grad = np.zeros(self.C.shape)\n",
    "        \n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        v = np.linalg.pinv(self.C.T @ self.L @ self.C + J)\n",
    "        grad += -2*self.gamma * self.L @ self.C @ v\n",
    "        \n",
    "        grad += self.alpha * (self.C @ self.X_tilde - self.X) @ self.X_tilde.T\n",
    "        grad += 2*self.L @ self.C @ self.X_tilde @ self.X_tilde.T\n",
    "        grad += self.lambd * np.abs(self.C) @ (np.ones((self.n, self.n)))\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def update_C(self):\n",
    "        self.C = self.C - self.lr * self.gradient_C()\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        for i in range(len(self.C)):\n",
    "            self.C[i] = self.C[i] / np.linalg.norm(self.C[i],1)\n",
    "        \n",
    "        return None\n",
    "\n",
    "  \n",
    "    def fit(self, max_iters):\n",
    "        loss = np.zeros(max_iters)\n",
    "        for i in tqdm(range(max_iters)):\n",
    "            for _ in range(MAX_C_ITER):\n",
    "                self.update_C()\n",
    "            self.update_X_tilde()\n",
    "            loss[i] = self.objective()\n",
    "            self.num_iter += 1\n",
    "        return (self.C, self.X_tilde, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70cea986-c429-49d7-8724-ab6ef1c7aba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:18<00:00,  1.88s/it]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "num_iter = 10\n",
    "\n",
    "# Hyperparameters: lambda, alpha, gamma\n",
    "obj = solver(L, X, n, 500, 500, X.shape[1]/2) \n",
    "C_0, X_t_0, loss_ls = obj.fit(num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99e8fe3a-ceb2-4736-a0fb-73252efa84dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1042858.5469177227,\n",
       " 927114.6925468271,\n",
       " 885678.6492330466,\n",
       " 868867.2941789497,\n",
       " 859007.1543449631,\n",
       " 854620.1061137915,\n",
       " 852924.1605778319,\n",
       " 851692.4810978615,\n",
       " 850895.1787722268,\n",
       " 850370.4848242351]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ec34971-86c4-4072-9eb6-e87db3808035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:19<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "obj_2 = GraphCoarsener(L, X, n, X.shape[1]/2, 500, 500)\n",
    "C_2, X_2, loss_2 = obj_2.fit(iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c746d74c-d312-490d-abc4-3ee44e067072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1081968.33008207,  940380.21633698,  868796.89777601,\n",
       "        851307.8478082 ,  846549.27728529,  844743.60925996,\n",
       "        843654.88322882,  842966.21609628,  842469.11532114,\n",
       "        842082.34809686])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e5e690-7e62-4260-8f67-19f293d3eaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
