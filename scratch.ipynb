{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d21f9a-f4c6-4ca8-b288-93e69a0f6e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({\"text.usetex\": True})\n",
    "plt.rc('xtick',labelsize=8)\n",
    "plt.rc('ytick',labelsize=8)\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d604e666-ca99-4c0d-96f9-43c714838fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FGC:\n",
    "    def __init__(self, L, X, n, gamma, lambd, alpha, seed = 666):\n",
    "        # Save parameter fields.\n",
    "        self.L = L\n",
    "        self.X = X\n",
    "        self.N = X.shape[0]\n",
    "        self.n = n\n",
    "        self.d = X.shape[1]\n",
    "        \n",
    "        # Initialize optimization variables as random matrices.\n",
    "        np.random.seed(seed)\n",
    "        self.X_tilde = np.random.normal(0, 1, (self.n, self.d))\n",
    "        \n",
    "        self.clip = 1e-10\n",
    "        self.C = np.random.normal(0, 1, (self.N, self.n))\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        # Save regularization variables.\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Optimization parameters.\n",
    "        self.num_iter = 0\n",
    "        self.lr = 1e-5\n",
    "        self.num_c_iter = 100\n",
    "\n",
    "    def objective(self):\n",
    "        f = 0\n",
    "        \n",
    "        # Bregman divergence.\n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        f += -self.gamma * np.linalg.slogdet(self.C.T @ self.L @ self.C + J)[1]\n",
    "        \n",
    "        # Dirichlet energy.\n",
    "        L_tilde = self.C.T @ self.L @ self.C\n",
    "        f += np.trace(self.X_tilde.T @ L_tilde @ self.X_tilde)\n",
    "\n",
    "        # Regularization for C.\n",
    "        f += self.lambd * np.linalg.norm(self.C @ np.ones((self.n, 1)))**2 / 2\n",
    "        \n",
    "        # Regularization for X_tilde.\n",
    "        f += self.alpha * np.linalg.norm(self.X - self.C @ self.X_tilde)**2 / 2\n",
    "        \n",
    "        return f\n",
    "\n",
    "    def update_X_tilde(self):\n",
    "        L_tilde = self.C.T @ self.L @ self.C\n",
    "        A = 2 * L_tilde / self.alpha + self.C.T @ self.C\n",
    "        self.X_tilde = np.linalg.pinv(A) @ self.C.T @ X\n",
    "\n",
    "        for i in range(len(self.X_tilde)):\n",
    "            self.X_tilde[i] = self.X_tilde[i] / np.linalg.norm(self.X_tilde[i])\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def gradient_C(self):\n",
    "        grad = np.zeros(self.C.shape)\n",
    "        \n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        v = np.linalg.pinv(self.C.T @ self.L @ self.C + J)\n",
    "        grad += -2*self.gamma * self.L @ self.C @ v\n",
    "        \n",
    "        grad += self.alpha * (self.C @ self.X_tilde - self.X) @ self.X_tilde.T\n",
    "        grad += 2*self.L @ self.C @ self.X_tilde @ self.X_tilde.T\n",
    "        grad += self.lambd * np.abs(self.C) @ (np.ones((self.n, self.n)))\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def update_C(self):\n",
    "        self.C = self.C - self.lr * self.gradient_C()\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        for i in range(len(self.C)):\n",
    "            self.C[i] = self.C[i] / np.linalg.norm(self.C[i],1)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def fit(self, num_iters):\n",
    "        loss = np.zeros(num_iters)\n",
    "        for i in tqdm(range(num_iters)):\n",
    "            for _ in range(self.num_c_iter):\n",
    "                self.update_C()\n",
    "            self.update_X_tilde()\n",
    "            loss[i] = self.objective()\n",
    "            self.num_iter += 1\n",
    "        return (self.C, self.X_tilde, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6aefd5-0896-4e67-8eea-59866396fd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GC:\n",
    "    def __init__(self, L, n, gamma, lambd, alpha, seed = 666, quiet = False):\n",
    "        # Save parameter fields.\n",
    "        self.L = L\n",
    "        self.N = L.shape[0]\n",
    "        self.n = n\n",
    "        \n",
    "        # Initialize optimization variables as random matrices.\n",
    "        self.clip = 1e-10\n",
    "        self.C = np.random.normal(0, 1, (self.N, self.n))\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        # Save regularization variables.\n",
    "        self.alpha = alpha\n",
    "        self.lambd = lambd\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # Optimization parameters.\n",
    "        self.num_iter = 0\n",
    "        self.lr = 1e-5\n",
    "        self.num_c_iter = 100\n",
    "        \n",
    "        # Turn off tqdm output.\n",
    "        self.quiet = quiet\n",
    "\n",
    "    def objective(self):\n",
    "        f = 0\n",
    "        \n",
    "        # Bregman divergence.\n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        f += -self.gamma * np.linalg.slogdet(self.C.T @ self.L @ self.C + J)[1]\n",
    "\n",
    "        # Regularization for C.\n",
    "        f += self.lambd * np.linalg.norm(self.C @ np.ones((self.n, 1)))**2 / 2\n",
    "        \n",
    "        return f\n",
    "\n",
    "    def gradient_C(self):\n",
    "        grad = np.zeros(self.C.shape)\n",
    "        \n",
    "        J = np.outer(np.ones(self.n), np.ones(self.n)) / self.n\n",
    "        v = np.linalg.pinv(self.C.T @ self.L @ self.C + J)\n",
    "        grad += -2*self.gamma * self.L @ self.C @ v\n",
    "        grad += self.lambd * np.abs(self.C) @ (np.ones((self.n, self.n)))\n",
    "\n",
    "        return grad\n",
    "\n",
    "    def update_C(self):\n",
    "        self.C = self.C - self.lr * self.gradient_C()\n",
    "        self.C[self.C < self.clip] = self.clip\n",
    "\n",
    "        for i in range(len(self.C)):\n",
    "            self.C[i] = self.C[i] / np.linalg.norm(self.C[i],1)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def fit(self, num_iters):\n",
    "        loss = np.zeros(num_iters)\n",
    "        for i in tqdm(range(num_iters), disable = self.quiet):\n",
    "            for _ in range(self.num_c_iter):\n",
    "                self.update_C()\n",
    "            loss[i] = self.objective()\n",
    "            self.num_iter += 1\n",
    "        return (self.C, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d148171-e3d5-49a8-9d92-abce9616da61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_LX(G, d, seed = None):\n",
    "    # Create edge weights\n",
    "    np.random.seed(seed)\n",
    "    N = len(G.nodes)\n",
    "    W = np.zeros((N, N))\n",
    "    for (x, y) in G.edges:\n",
    "        W[x][y] = np.random.randint(1,10)\n",
    "    W = W + W.T\n",
    "\n",
    "    # Compute Laplacian\n",
    "    D = np.diag(W @ np.ones((W.shape[0])))\n",
    "    L = D - W\n",
    "\n",
    "    # Create features for the synthetic graph\n",
    "    X = np.random.multivariate_normal(np.zeros(N), np.linalg.pinv(L), d).T\n",
    "    \n",
    "    return L, X\n",
    "\n",
    "def make_erdos_renyi_graph(N, p, d, seed = None):\n",
    "    G = nx.erdos_renyi_graph(N, p, directed = False)\n",
    "    return make_LX(G, d, seed)\n",
    "\n",
    "def make_barabasi_albert_graph(N, m, d, seed = None):\n",
    "    G = nx.barabasi_albert_graph(n = N, m = m, seed = seed)\n",
    "    return make_LX(G, d, seed)\n",
    "\n",
    "def make_watts_strogatz_graph(N, k, p, d, seed = None):\n",
    "    G = nx.watts_strogatz_graph(N, k, p, seed = seed)\n",
    "    return make_LX(G, d, seed)\n",
    "\n",
    "def make_random_geometric_graph(N, r, d, seed = None):\n",
    "    # Make graph\n",
    "    G = nx.random_geometric_graph(N, r, seed = seed)\n",
    "    return make_LX(G, d, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db2109af-4450-4c32-a7b9-002760689425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reconstruction_error(L, L_hat):\n",
    "    return np.linalg.norm(L - L_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d85fba8-e97f-4731-b46c-dd6a88bd1c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "L, X = make_erdos_renyi_graph(100, 0.9, 500)\n",
    "#L, X = make_barabasi_albert_graph(N, 20, 500)\n",
    "#L, X = make_watts_strogatz_graph(N, 20, 0.1, 500)\n",
    "#L, X = make_barabasi_albert_graph(N, 20, 500)\n",
    "#L, X = make_random_geometric_graph(100, 0.1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90a59d18-f885-4386-8123-2689a28cc1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.07it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "num_iter = 100\n",
    "\n",
    "fgc = GC(L, n, 500, 500, X.shape[1]/2) \n",
    "C, loss = fgc.fit(num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "462f629e-ce52-4a35-b912-90d099ba5d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20193.66178193, 20153.44689702, 20136.499304  , 20129.5046158 ,\n",
       "       20102.05673057, 20043.78325151, 20020.62458534, 20006.77337932,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967,\n",
       "       20002.42262967, 20002.42262967, 20002.42262967, 20002.42262967])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e96523f-152b-45eb-87ac-09517de2cf55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = np.linalg.pinv(C)\n",
    "H = np.round(C @ P, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9410ea5a-9216-4192-9f72-2d210c7bf07a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02,  0.  ,  0.02, ...,  0.02,  0.02, -0.  ],\n",
       "       [ 0.  ,  0.02,  0.  , ...,  0.  ,  0.  ,  0.02],\n",
       "       [ 0.02,  0.  ,  0.02, ...,  0.02,  0.02,  0.  ],\n",
       "       ...,\n",
       "       [ 0.02,  0.  ,  0.02, ...,  0.02,  0.02,  0.  ],\n",
       "       [ 0.02,  0.  ,  0.02, ...,  0.02,  0.02, -0.  ],\n",
       "       [-0.  ,  0.02,  0.  , ...,  0.  , -0.  ,  0.02]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c1ea7b2-e082-43b9-9d64-65a0c1f90d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  , -0.  ],\n",
       "       [ 0.  , -0.01,  0.  , ...,  0.  ,  0.  , -0.01],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  , -0.  ],\n",
       "       [-0.  , -0.01,  0.  , ...,  0.  ,  0.  , -0.01]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H - np.round(np.linalg.pinv(H), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7ecf40-858c-4b6a-bda2-aee313df69e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gracoa",
   "language": "python",
   "name": "gracoa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
